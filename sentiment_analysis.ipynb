{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tshanmukh/sentiment_analysis/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWkYBE5QO2n",
        "colab_type": "text"
      },
      "source": [
        "# sentiment analysis project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_fl1tQQR9I",
        "colab_type": "code",
        "outputId": "d579a5df-e244-48af-9ffe-b23ca63a2302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGUbY62SQWNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xunShkUVQO2o",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess and prepare a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuCvslpPQO2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQOYHxzFQO2t",
        "colab_type": "code",
        "outputId": "afe5dbb9-23b2-4bf7-96b5-0dff57c6375f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reading the data to a csv\n",
        "# Reading the data from csv\n",
        "train_csv = pd.read_csv(root_path+'dataset/train.csv')\n",
        "print(len(train_csv.text))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOWOexDMQO2z",
        "colab_type": "code",
        "outputId": "608e5035-9bcc-4c4e-988a-58a1ed2938d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "punctuation\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyEf1YQQO23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = ' '.join(list(train_csv.text))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq5UKIsutvT6",
        "colab_type": "text"
      },
      "source": [
        "## Creating a complete text in train csv to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVVGstDNQO29",
        "colab_type": "code",
        "outputId": "eb7016e3-de1f-443b-83ea-f955fcb8906d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import string\n",
        "\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()\n",
        "words[30:60]"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taking',\n",
              " 'tysabri',\n",
              " 'and',\n",
              " 'feel',\n",
              " 'amazing',\n",
              " 'no',\n",
              " 'symptoms',\n",
              " 'other',\n",
              " 'than',\n",
              " 'dodgy',\n",
              " 'color',\n",
              " 'vision',\n",
              " 'but',\n",
              " 'i’ve',\n",
              " 'had',\n",
              " 'it',\n",
              " 'since',\n",
              " 'always',\n",
              " 'so',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'and',\n",
              " 'i',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'if',\n",
              " 'it',\n",
              " 'will',\n",
              " 'last',\n",
              " 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-b3_kyt4iz",
        "colab_type": "text"
      },
      "source": [
        "## Removing the punctuation, hyphen, and dash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F5g00jkQO3A",
        "colab_type": "code",
        "outputId": "eb448ec2-e6f3-4e62-b066-4455b18a92f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "print(stripped[:100])\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['autoimmune', 'diseases', 'tend', 'to', 'come', 'in', 'clusters', 'as', 'for', 'gilenya', '', 'if', 'you', 'feel', 'good', 'dont', 'think', 'about', 'it', 'it', 'wont', 'change', 'anything', 'but', 'waste', 'your', 'time', 'and', 'energy', 'im', 'taking', 'tysabri', 'and', 'feel', 'amazing', 'no', 'symptoms', 'other', 'than', 'dodgy', 'color', 'vision', 'but', 'ive', 'had', 'it', 'since', 'always', 'so', 'dont', 'know', 'and', 'i', 'dont', 'know', 'if', 'it', 'will', 'last', 'a', 'month', 'a', 'year', 'a', 'decade', 'ive', 'just', 'decided', 'to', 'enjoy', 'the', 'ride', 'no', 'point', 'in', 'worrying', 'i', 'can', 'completely', 'understand', 'why', 'youd', 'want', 'to', 'try', 'it', 'but', 'results', 'reported', 'in', 'lectures', 'dont', 'always', 'stand', 'up', 'to', 'the', 'scrutiny', 'of', 'peerreview']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Awp23YQO3E",
        "colab_type": "code",
        "outputId": "8df97829-2ba3-432d-b3ea-b380f6711843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(stripped))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1786150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtEcpppyuCp_",
        "colab_type": "text"
      },
      "source": [
        "## Removing the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFyDfG2aQO3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_words = [word for word in stripped if word not in stopwords.words('english')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceKFWZxfQO3J",
        "colab_type": "code",
        "outputId": "0a7eb9c2-6b89-49ef-9148-ba960b64e262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(new_words)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1058756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kub8nHUQO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabulary_latest = [word for word in new_words if len(word) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9s2ZJQJQO3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(vocabulary_latest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFx6NEbfQO3X",
        "colab_type": "text"
      },
      "source": [
        "# pickling the progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V528nPX7QO3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6h9pnVQO3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = open(root_path + 'pickle/vocabulary.pickle','wb')\n",
        "\n",
        "pickle.dump(new_words, vocabulary)\n",
        "\n",
        "vocabulary.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJlm1iZxuzbC",
        "colab_type": "text"
      },
      "source": [
        "## saved the progress of pre processing \n",
        "### Start from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKtgPNUvfyD",
        "colab_type": "code",
        "outputId": "042b0882-fd63-4e69-e996-39dff307604e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9N8uwuou5xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDRCZdgMQO3e",
        "colab_type": "code",
        "outputId": "8ed79222-9377-480a-dca2-f7904e33ac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = open(root_path + 'pickle/vocabulary.pickle','rb')\n",
        "words = pickle.load(file)\n",
        "len(words), type(words)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1058756, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_hP88U0QO3j",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizing the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NDwghhrQO3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feel free to use this import \n",
        "from collections import Counter\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "int_to_vocab = {ii: word for ii, word in enumerate(vocab, 1)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHDEa4cQO3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int_pickle = open(root_path  + 'pickle/vocab_to_int.pickle','wb')\n",
        "int_to_vocab_pickle = open(root_path + 'pickle/int_to_vocab.pickle','wb')\n",
        "\n",
        "pickle.dump(vocab_to_int,vocab_to_int_pickle)\n",
        "pickle.dump(int_to_vocab,int_to_vocab_pickle)\n",
        "\n",
        "vocab_to_int_pickle.close()\n",
        "int_to_vocab_pickle.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLZnIuFQO3z",
        "colab_type": "text"
      },
      "source": [
        "# Functions to tokenize the raw review and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgbAwvPTw-q7",
        "colab_type": "code",
        "outputId": "139a730f-d9c6-4b77-93b1-260b17d7ee7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klR3E_cTQO30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def tokenize_review(review):\n",
        "    \n",
        "    words = review.lower().split(' ')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    review = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "    # review = ''.join([c for c in review if c not in punctuation])\n",
        "    tokens = []\n",
        "    for word in review:\n",
        "      \n",
        "        try:\n",
        "            token = vocab_to_int[word]\n",
        "            # print(word, token)\n",
        "        except KeyError:\n",
        "            token = 0\n",
        "            # print(word, token)\n",
        "        tokens.append(token)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HciTJCm7QO32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "review_tokens = tokenize_review(list(train_csv.text)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaFKMYfQO36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_setiment(label):\n",
        "  if label == '0' or label == 0:\n",
        "    return 0\n",
        "  elif label == '1' or label == 1:\n",
        "    return 1\n",
        "  elif label == '2' or label == 2:\n",
        "    return 2\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GupoQj5kUUUe",
        "colab_type": "code",
        "outputId": "bf243854-ced7-4199-a619-c8af3b93092b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenize_setiment(list(train_csv.sentiment)[2000])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdzyz_ZtxU-B",
        "colab_type": "text"
      },
      "source": [
        "## parse the review based on the drug and tokenize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHH4Qd_c06gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "drugs = set([w.translate(table).replace('’','').replace('–','').lower() for w in set(train_csv.drug)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFloY63cUiHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import LineTokenizer\n",
        "\n",
        "def parse_review(review, drug, drugs_list):\n",
        "  tk = LineTokenizer()\n",
        "  lines = tk.tokenize(review)\n",
        "  review = ''.join(lines)\n",
        "  sentenses = review.lower().split('.')\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  drugs_list.remove(drug)\n",
        "  drug = drug.translate(table).replace('’','').replace('–','').lower()\n",
        "  token =[]\n",
        "  for sentense in sentenses:\n",
        "    review = set([w.translate(table).replace('’','').replace('–','') for w in sentense.split(' ') if w != ''])\n",
        "    \n",
        "      # print(\"Not expecting\", drugs_list & review, \"expecting only \",drug)\n",
        "    \n",
        "    token.extend(tokenize_review(sentense))\n",
        "  return token\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTnsKC2i4kz",
        "colab_type": "code",
        "outputId": "8f1ab7c3-e1c1-493b-b044-5f51a59b89e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(train_csv.loc[10,'text'])\n",
        "print(train_csv.loc[10,'drug'])\n",
        "drugs_list = drugs.copy()\n",
        "# print(len(train_csv.loc[10,'text'].split(' ')))\n",
        "token = parse_review(train_csv.loc[10,'text'],train_csv.loc[10,'drug'], drugs_list)\n",
        "print(token)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have no vision in one eye, unrelated to my eye injections. However, when problems began in my good eye, getting injections in that one and only eye is always a horrifying experience - mentally. It is still scary till today, you don't get used to it. I have had many eye injections. My first was when I was 43 years old, 7 years ago. I developed an eye infection, but no one could pinpoint what it exactly was. So one by one, every antibiotic was injected in the eye for a period of 6 weeks, and totalling 24 injections. It was a big relief when the last antibiotic available did the job, as there were no other options left after that. Two years later, I had cataract surgery. Within a week I developed retinal vein occlusion. Also, macular oedema came into play as well. And so began the Avasrin injections and then Lucentis. I would be getting them very frequently. And a year later, it became monthly injections. I have now stopped counting. Sometimes after an injection, it becomes pitch black for me. The first time I was terrified. But then I was told it was due to eye pressured and after a few Injures, all came back to normal. Main thing is I make sure what may or may not happen with the procedure and eye condition, so at least I am prepared. It's true, in Australia, neither Lucentis nor Eylea were covered by the government unless one had macular degeneration. Even though the other conditions are also vision threatening. Eylea has extended the time period between each of my injections, and that is the biggest milestone achieved to date. I am so grateful to my ALL of my ophthalmologists who have gone above and beyond their profession, to make the injection process as comfortable as they possibly can for me. And as for the researchers, well done and keep it going. The eye is priceless.\n",
            "lucentis\n",
            "[0, 0, 0, 242, 0, 8, 152, 4836, 0, 0, 152, 349, 70, 136, 0, 180, 851, 0, 0, 42, 152, 158, 349, 0, 0, 8, 0, 0, 152, 0, 292, 0, 12838, 270, 70, 4529, 70, 0, 0, 57, 1931, 2968, 273, 0, 52, 18, 39, 0, 0, 70, 0, 0, 0, 69, 152, 349, 70, 0, 22, 0, 0, 0, 0, 2214, 10, 391, 249, 10, 124, 70, 0, 436, 0, 152, 160, 0, 0, 8, 44, 6880, 0, 0, 1652, 0, 70, 0, 8, 0, 8, 66, 2969, 0, 1287, 0, 0, 152, 0, 0, 600, 0, 77, 34, 0, 20323, 546, 349, 70, 0, 0, 0, 466, 1499, 0, 0, 79, 2969, 135, 0, 0, 1247, 0, 0, 0, 0, 0, 290, 339, 0, 0, 70, 35, 10, 360, 0, 0, 1127, 45, 70, 277, 0, 78, 0, 436, 537, 993, 1871, 70, 7, 347, 1687, 592, 0, 1320, 0, 36, 70, 0, 0, 851, 0, 28570, 349, 0, 0, 1033, 70, 0, 19, 0, 158, 0, 0, 1500, 70, 0, 0, 48, 360, 0, 1341, 1265, 349, 70, 0, 0, 0, 522, 6123, 70, 355, 0, 0, 178, 0, 1653, 11579, 1851, 0, 0, 70, 0, 22, 16, 0, 0, 4955, 70, 0, 0, 0, 0, 245, 0, 0, 199, 0, 152, 14334, 0, 0, 0, 0, 20324, 0, 592, 58, 0, 312, 70, 793, 288, 0, 0, 88, 182, 0, 4, 0, 4, 0, 892, 0, 0, 740, 0, 152, 429, 0, 0, 187, 0, 0, 2669, 70, 0, 1377, 0, 1838, 2830, 1033, 0, 804, 0, 1852, 0, 0, 2091, 1113, 8, 0, 347, 934, 70, 74, 313, 0, 0, 539, 0, 7, 242, 5734, 70, 804, 0, 2393, 0, 16, 600, 0, 0, 0, 0, 349, 0, 0, 0, 0, 2092, 5920, 1721, 0, 692, 70, 0, 0, 0, 2237, 0, 0, 0, 0, 0, 6881, 0, 0, 874, 0, 0, 1321, 0, 10675, 0, 88, 0, 178, 586, 0, 2583, 0, 0, 1147, 0, 0, 0, 70, 0, 0, 0, 0, 388, 36, 198, 0, 181, 0, 111, 70, 0, 152, 0, 28571, 70]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOCTvf6FHcd",
        "colab_type": "text"
      },
      "source": [
        "# Creating a dataset from the train_csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRhudvPRFGe1",
        "colab_type": "code",
        "outputId": "e68785f3-87fa-486e-a4ef-d039cfb2339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "text_dataset = []\n",
        "label_dataset = []\n",
        "for review in tqdm(zip(train_csv.text, train_csv.drug, train_csv.sentiment)):\n",
        "  drugs_list = drugs.copy()\n",
        "  text_dataset.append(parse_review(review[0],review[1].translate(table).replace('’','').replace('–','').lower(), drugs_list)) #added the preprocess for drugname\n",
        "  label_dataset.append(tokenize_setiment(review[2]))"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "65it [00:00, 648.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "200it [00:00, 765.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "314it [00:00, 848.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "417it [00:00, 895.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "498it [00:00, 837.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "626it [00:00, 931.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "733it [00:00, 968.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "837it [00:00, 986.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "937it [00:00, 982.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1062it [00:01, 1049.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1169it [00:01, 1023.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1273it [00:01, 1010.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1375it [00:01, 922.10it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1470it [00:01, 887.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1580it [00:01, 940.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1677it [00:01, 827.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1781it [00:01, 869.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1872it [00:01, 823.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1992it [00:02, 908.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2088it [00:02, 844.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2177it [00:02, 788.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2299it [00:02, 881.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2399it [00:02, 914.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2498it [00:02, 935.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2595it [00:02, 880.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2702it [00:02, 928.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2830it [00:02, 1011.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2947it [00:03, 1053.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3105it [00:03, 1164.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3234it [00:03, 1193.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3358it [00:03, 1116.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3474it [00:03, 1018.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3582it [00:03, 1034.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3689it [00:03, 1000.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3817it [00:03, 1069.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3928it [00:03, 1064.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4037it [00:04, 1032.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4202it [00:04, 1163.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4326it [00:04, 1096.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4450it [00:04, 1129.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4568it [00:04, 1120.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4711it [00:04, 1196.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4835it [00:04, 1133.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4952it [00:04, 1134.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5074it [00:04, 1155.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5192it [00:05, 1086.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5279it [00:05, 1032.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7uXLe8qqg6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edaa2b05-e57c-4f1d-edd3-27456b8b01af"
      },
      "source": [
        "len(text_dataset), len(label_dataset) "
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279, 5279)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmsf2U7gH1d4",
        "colab_type": "code",
        "outputId": "a8850a41-a3cb-430c-f893-04b04982a977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "reviews_ints = text_dataset.copy()\n",
        "encoded_labels = label_dataset.copy()\n",
        "\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  5279\n",
            "Number of reviews after removing outliers:  5279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz9WYvyjKFjB",
        "colab_type": "code",
        "outputId": "351ae0dc-69a1-4dcb-f71b-93076db91bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_dataset, label_dataset = None, None\n",
        "print(encoded_labels)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 ... 2 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5RrcSjbAFTw",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJz351qfEREx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUgibrRQi4kD",
        "colab_type": "code",
        "outputId": "e2bfea4a-68fb-48f2-b4c8-9e8ca2c7bbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "lengths =[]\n",
        "for rev in reviews_ints:\n",
        "  lengths.append(len(rev))\n",
        "print(max(lengths))\n",
        "%matplotlib inline\n",
        "plt.plot(lengths)\n",
        "plt.show()\n",
        "\n",
        "# sum(lengths)/len(lengths)\n",
        "lengths = None"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ig4iIhInP8PXv/Yfu8Cs6QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQY6eyR9i4jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMV96afqi4h5",
        "colab_type": "code",
        "outputId": "bfce05e8-d9ac-476c-d3fd-fa050766b26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_length = 1400\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "# ## test statements - do not change - ##\n",
        "# assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "# assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches \n",
        "print(features.shape)"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5279, 1400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7wBZc9CK3DB",
        "colab_type": "text"
      },
      "source": [
        "# Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoIJq-jg3Am",
        "colab_type": "code",
        "outputId": "0b9fe5b5-25fc-4dfc-f179-f2814bf0b8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "# test_idx = int(len(remaining_x)*0.5)\n",
        "# val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "# val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "val_x = remaining_x\n",
        "val_y = remaining_y\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape))\n",
        "\n",
        "features= None\n",
        "train_y.shape"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(4223, 1400) \n",
            "Validation set: \t(1056, 1400)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4223,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlRw02JULJGM",
        "colab_type": "text"
      },
      "source": [
        "# dataloaders and batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZb81qlKK_4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "# test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "# test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1icgJNfJnScL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUz-DGksLHPz",
        "colab_type": "code",
        "outputId": "ef2e5c83-4e72-4074-ca4b-7f85ee0b3805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 1400])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,  1536,   594,  5466],\n",
            "        [    0,     0,     0,  ...,     0,   785,    70],\n",
            "        [    0,     0,     0,  ...,  1498,     0,    16],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,     0, 12040,    70],\n",
            "        [    0,     0,     0,  ...,    36,     0,    70],\n",
            "        [    0,     0,     0,  ...,    70,    42,   711]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2,\n",
            "        1, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 2,\n",
            "        1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFvmRcCcL1ux",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-r6MZk0LtMp",
        "colab_type": "code",
        "outputId": "e2f00234-4b2d-402e-bbb4-973f6b3d63db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "  print(\"Training on GPU\")\n",
        "else:\n",
        "  print('No GPU available. Training on CPU')"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV-cz0ngMAvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # print(out.shape)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        # sig_out = out\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1, 3)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pApisARZRVAf",
        "colab_type": "code",
        "outputId": "fd92f19c-6f9c-476c-f4f9-b5f8a75cc5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "\n",
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(53133, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (sig): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2YsLZHRbph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPr7yJLhTqYm",
        "colab_type": "code",
        "outputId": "1b67bf6b-c7e5-4194-b711-c907a501f13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "\n",
        "# training params\n",
        "\n",
        "epochs = 25 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "    # net.to('cuda')\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        # labels = torch.tensor(labels, dtype=torch.long)\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "        # print(inputs.shape)\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "        # print(output.shape, labels.shape)\n",
        "        # calculate the loss and perform backprop\n",
        "       \n",
        "        loss = criterion(output.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.squeeze())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(val_loss))\n",
        "\n"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 100... Loss: 0.918202... Val Loss: 0.801973\n",
            "Epoch: 2/25... Step: 200... Loss: 0.754148... Val Loss: 0.793168\n",
            "Epoch: 3/25... Step: 300... Loss: 0.418891... Val Loss: 1.009425\n",
            "Epoch: 4/25... Step: 400... Loss: 0.298579... Val Loss: 1.068025\n",
            "Epoch: 5/25... Step: 500... Loss: 0.158487... Val Loss: 1.783535\n",
            "Epoch: 7/25... Step: 600... Loss: 0.030991... Val Loss: 1.466086\n",
            "Epoch: 8/25... Step: 700... Loss: 0.038215... Val Loss: 2.579368\n",
            "Epoch: 9/25... Step: 800... Loss: 0.011723... Val Loss: 1.375808\n",
            "Epoch: 10/25... Step: 900... Loss: 0.065060... Val Loss: 1.715047\n",
            "Epoch: 11/25... Step: 1000... Loss: 0.170156... Val Loss: 2.133847\n",
            "Epoch: 13/25... Step: 1100... Loss: 0.041771... Val Loss: 1.959725\n",
            "Epoch: 14/25... Step: 1200... Loss: 0.012920... Val Loss: 1.728476\n",
            "Epoch: 15/25... Step: 1300... Loss: 0.065297... Val Loss: 2.027033\n",
            "Epoch: 16/25... Step: 1400... Loss: 0.063391... Val Loss: 2.946314\n",
            "Epoch: 17/25... Step: 1500... Loss: 0.117685... Val Loss: 1.402247\n",
            "Epoch: 19/25... Step: 1600... Loss: 0.086684... Val Loss: 3.019981\n",
            "Epoch: 20/25... Step: 1700... Loss: 0.039275... Val Loss: 2.963635\n",
            "Epoch: 21/25... Step: 1800... Loss: 0.071171... Val Loss: 2.803038\n",
            "Epoch: 22/25... Step: 1900... Loss: 0.016165... Val Loss: 3.150737\n",
            "Epoch: 23/25... Step: 2000... Loss: 0.036680... Val Loss: 1.892466\n",
            "Epoch: 24/25... Step: 2100... Loss: 0.010219... Val Loss: 2.781376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_oh_wFWnQ0",
        "colab_type": "text"
      },
      "source": [
        "## Loading and testing the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZX64riBTxhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "# model_test = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "# model_test.load_state_dict(torch.load(root_path+'/model.pt'),strict=False)\n",
        "# if train_on_gpu:\n",
        "#   print(\"using GPU\")\n",
        "#   model_test.cuda()\n",
        "# model_test.eval()\n",
        "\n",
        "# for param in model_test.parameters():\n",
        "#   print(param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iicRcHshW9RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f42f13ef-6483-46ca-cdc8-010e69999f23"
      },
      "source": [
        "test_csv = pd.read_csv(root_path + 'dataset/test.csv')\n",
        "test_csv.head()"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>On fingolimod and have been since December 201...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
              "      <td>humira</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
              "      <td>tagrisso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
              "      <td>stelara</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ...        drug\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08  ...  fingolimod\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  ...  fingolimod\n",
              "2  50b6d851bcff4f35afe354937949e9948975adf7  ...      humira\n",
              "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae  ...    tagrisso\n",
              "4  8b37d169dee5bdae27060949242fb54feb6a7f7f  ...     stelara\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDHUBe6qYYNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d99f70ae-9c0d-4173-cb1e-82a3f7cabe4c"
      },
      "source": [
        "# parse_review(review[0],review[1].translate(table).replace('’','').replace('–','').lower(), drugs_list)\n",
        "\n",
        "list(test_csv.text)[20], list(test_csv.drug)[20],"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"You are overthinking this. Just ask her out and see if she accepts first. If she says yes, then you can discuss where you'd like to go that would suit both of you. If she wants to talk about her Crohn's, then listen to her, but I wouldn't mention it until she does to be honest. Ditto the unsympathetic ex. Dx Crohn's in June 2000. (Yay  ) Tried: 5-ASAs, azathioprine, 6MP, Remicade, methotrexate, Humira, diets. 1st surgery 20/2/13 - subtotal colectomy with end ileostomy. 2nd surgery 10/7/15 - ileorectal anastomosis. Stoma reversed and ileum connected to the rectum. Current status: Chronic flare. Do I have any other kind? Current meds: 50mg 6MP; Entyvio (started 3/11/16)\",\n",
              " 'remicade')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVBYk_YZyRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijX0xsyaWkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_sentiment(review, drug):\n",
        "#   drugs_list = drugs.copy()\n",
        "#   test_review = parse_review(list(test_csv.text)[200], list(test_csv.drug)[200], drugs_list)\n",
        "#   test_input = pad_features([test_review], 600)\n",
        "#   test_input = np.array(test_input)\n",
        "#   # initialize hidden state\n",
        "#   h = net.init_hidden(2)\n",
        "#   feature_tensor = torch.from_numpy(test_input)\n",
        "    \n",
        "#   # batch_size = feature_tensor.size(0)\n",
        "#   if(train_on_gpu):\n",
        "#     feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "#   # get the output from the model\n",
        "#   output, h = net(feature_tensor, h)  \n",
        "#   return torch.exp(output).topk(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNydsvF_b_so",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkLhYqpl9ZIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def tok_rev(review):\n",
        "    \n",
        "    words = review.lower().split(' ')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    review = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "    # review = ''.join([c for c in review if c not in punctuation])\n",
        "    tokens = []\n",
        "    for word in review:\n",
        "      \n",
        "        try:\n",
        "            token = vocab_to_int[word]\n",
        "            # print(word, token)\n",
        "        except KeyError:\n",
        "            token = 0\n",
        "            # print(word, token)\n",
        "        tokens.append(token)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ0a3HEp96lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    reviews_ints = [reviews_ints]\n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI5Zx_HX8E5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize review\n",
        "    test_ints = tok_rev(test_review)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    # printing output value, before rounding\n",
        "    return torch.exp(output).topk(3).indices.to('cpu').numpy()[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLivckmcLz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffeac1d7-592b-46fa-877e-7bd396a28887"
      },
      "source": [
        "value = predict(net, list(test_csv.text)[20])\n",
        "value"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqKw_rYac6Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(root_path+'submission.csv','w')\n",
        "file.write(\"unique_hash,sentiment\\n\")\n",
        "a = set()\n",
        "for i in zip(test_csv.unique_hash, test_csv.text, test_csv.drug):\n",
        "  logits = predict(net, i[1])\n",
        "  file.write(\"{},{}\\n\".format(i[0],logits))\n",
        "  a.add(logits)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Z8wn6icW0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acba6ae8-da78-4148-8d35-23d7ef2da7a8"
      },
      "source": [
        "sub = pd.read_csv(root_path+'submission.csv')\n",
        "set(sub.sentiment)\n",
        "a"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVejbLTldz-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}