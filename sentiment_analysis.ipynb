{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment analyis project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and prepare a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import plotly.offline as pyo\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5279\n"
     ]
    }
   ],
   "source": [
    "# Reading the data to a csv\n",
    "# Reading the data from csv\n",
    "train_csv = pd.read_csv('dataset/train.csv')\n",
    "print(len(train_csv.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ' '.join(list(train_csv.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoimmune diseases tend to come in clusters. as for gilenya – if you feel good, don’t think about i\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['autoimmune',\n",
       " 'diseases',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'come',\n",
       " 'in',\n",
       " 'clusters',\n",
       " 'as',\n",
       " 'for',\n",
       " 'gilenya',\n",
       " '–',\n",
       " 'if',\n",
       " 'you',\n",
       " 'feel',\n",
       " 'good',\n",
       " 'don’t',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it',\n",
       " 'it',\n",
       " 'won’t',\n",
       " 'change',\n",
       " 'anything',\n",
       " 'but',\n",
       " 'waste',\n",
       " 'your',\n",
       " 'time',\n",
       " 'and',\n",
       " 'energy',\n",
       " 'i’m',\n",
       " 'taking',\n",
       " 'tysabri',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'amazing',\n",
       " 'no',\n",
       " 'symptoms',\n",
       " 'other',\n",
       " 'than',\n",
       " 'dodgy',\n",
       " 'color',\n",
       " 'vision',\n",
       " 'but',\n",
       " 'i’ve',\n",
       " 'had',\n",
       " 'it',\n",
       " 'since',\n",
       " 'always',\n",
       " 'so',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'and',\n",
       " 'i',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'if',\n",
       " 'it',\n",
       " 'will',\n",
       " 'last',\n",
       " 'a',\n",
       " 'month',\n",
       " 'a',\n",
       " 'year',\n",
       " 'a',\n",
       " 'decade',\n",
       " 'ive',\n",
       " 'just',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'enjoy',\n",
       " 'the',\n",
       " 'ride',\n",
       " 'no',\n",
       " 'point',\n",
       " 'in',\n",
       " 'worrying',\n",
       " 'i',\n",
       " 'can',\n",
       " 'completely',\n",
       " 'understand',\n",
       " 'why',\n",
       " 'you’d',\n",
       " 'want',\n",
       " 'to',\n",
       " 'try',\n",
       " 'it',\n",
       " 'but',\n",
       " 'results',\n",
       " 'reported',\n",
       " 'in',\n",
       " 'lectures',\n",
       " 'don’t',\n",
       " 'always',\n",
       " 'stand',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'scrutiny',\n",
       " 'of',\n",
       " 'peerreview']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.lower() # lowercase, standardize\n",
    "print(reviews[0:100])\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "\n",
    "# split by new lines and spaces\n",
    "reviews_split = all_text.split('\\n')\n",
    "all_text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()\n",
    "words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports for nltk stop words\n",
    "# Load library\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# You will have to download the set of stop words the first time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoimmune',\n",
       " 'diseases',\n",
       " 'tend',\n",
       " 'come',\n",
       " 'clusters',\n",
       " 'gilenya',\n",
       " '–',\n",
       " 'feel',\n",
       " 'good',\n",
       " 'don’t',\n",
       " 'think',\n",
       " 'won’t',\n",
       " 'change',\n",
       " 'anything',\n",
       " 'waste',\n",
       " 'time',\n",
       " 'energy',\n",
       " 'i’m',\n",
       " 'taking',\n",
       " 'tysabri',\n",
       " 'feel',\n",
       " 'amazing',\n",
       " 'symptoms',\n",
       " 'dodgy',\n",
       " 'color',\n",
       " 'vision',\n",
       " 'i’ve',\n",
       " 'since',\n",
       " 'always',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'last',\n",
       " 'month',\n",
       " 'year',\n",
       " 'decade',\n",
       " 'ive',\n",
       " 'decided',\n",
       " 'enjoy',\n",
       " 'ride',\n",
       " 'point',\n",
       " 'worrying',\n",
       " 'completely',\n",
       " 'understand',\n",
       " 'you’d',\n",
       " 'want',\n",
       " 'try',\n",
       " 'results',\n",
       " 'reported',\n",
       " 'lectures',\n",
       " 'don’t',\n",
       " 'always',\n",
       " 'stand',\n",
       " 'scrutiny',\n",
       " 'peerreview',\n",
       " 'publication',\n",
       " 'much',\n",
       " 'still',\n",
       " 'convincing',\n",
       " 'hope',\n",
       " 'work',\n",
       " 'really',\n",
       " 'you’re',\n",
       " 'aware',\n",
       " 'happy',\n",
       " 'risks',\n",
       " 'that’s',\n",
       " 'great',\n",
       " 'think',\n",
       " 'it’s',\n",
       " 'important',\n",
       " 'present',\n",
       " 'balanced',\n",
       " 'way',\n",
       " 'understand',\n",
       " 'don’t',\n",
       " 'move',\n",
       " 'straight',\n",
       " 'first',\n",
       " 'show',\n",
       " 'promise',\n",
       " 'animal',\n",
       " 'study',\n",
       " 'using',\n",
       " 'drugs',\n",
       " 'humans',\n",
       " 'there’s',\n",
       " 'still',\n",
       " 'lot',\n",
       " 'animal',\n",
       " 'data',\n",
       " 'gather',\n",
       " 'human',\n",
       " 'data',\n",
       " 'gather',\n",
       " 'anyone',\n",
       " 'tell',\n",
       " 'it’s',\n",
       " 'safe']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words = [word for word in words if word not in stopwords.words('english')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060060"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_latest = [word for word in new_words if len(word) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoimmune',\n",
       " 'diseases',\n",
       " 'tend',\n",
       " 'come',\n",
       " 'clusters',\n",
       " 'gilenya',\n",
       " 'feel',\n",
       " 'good',\n",
       " 'don’t',\n",
       " 'think',\n",
       " 'won’t',\n",
       " 'change',\n",
       " 'anything',\n",
       " 'waste',\n",
       " 'time',\n",
       " 'energy',\n",
       " 'i’m',\n",
       " 'taking',\n",
       " 'tysabri',\n",
       " 'feel',\n",
       " 'amazing',\n",
       " 'symptoms',\n",
       " 'dodgy',\n",
       " 'color',\n",
       " 'vision',\n",
       " 'i’ve',\n",
       " 'since',\n",
       " 'always',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'don’t',\n",
       " 'know',\n",
       " 'last',\n",
       " 'month',\n",
       " 'year',\n",
       " 'decade',\n",
       " 'ive',\n",
       " 'decided',\n",
       " 'enjoy',\n",
       " 'ride',\n",
       " 'point',\n",
       " 'worrying',\n",
       " 'completely',\n",
       " 'understand',\n",
       " 'you’d',\n",
       " 'want',\n",
       " 'try',\n",
       " 'results',\n",
       " 'reported',\n",
       " 'lectures',\n",
       " 'don’t',\n",
       " 'always',\n",
       " 'stand',\n",
       " 'scrutiny',\n",
       " 'peerreview',\n",
       " 'publication',\n",
       " 'much',\n",
       " 'still',\n",
       " 'convincing',\n",
       " 'hope',\n",
       " 'work',\n",
       " 'really',\n",
       " 'you’re',\n",
       " 'aware',\n",
       " 'happy',\n",
       " 'risks',\n",
       " 'that’s',\n",
       " 'great',\n",
       " 'think',\n",
       " 'it’s',\n",
       " 'important',\n",
       " 'present',\n",
       " 'balanced',\n",
       " 'way',\n",
       " 'understand',\n",
       " 'don’t',\n",
       " 'move',\n",
       " 'straight',\n",
       " 'first',\n",
       " 'show',\n",
       " 'promise',\n",
       " 'animal',\n",
       " 'study',\n",
       " 'using',\n",
       " 'drugs',\n",
       " 'humans',\n",
       " 'there’s',\n",
       " 'still',\n",
       " 'lot',\n",
       " 'animal',\n",
       " 'data',\n",
       " 'gather',\n",
       " 'human',\n",
       " 'data',\n",
       " 'gather',\n",
       " 'anyone',\n",
       " 'tell',\n",
       " 'it’s',\n",
       " 'safe',\n",
       " 'effective']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_latest[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickling the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_vocabulary = open('./pickle/complete_vocabulary.pickle','wb')\n",
    "vocabulary_g3 = open('./pickle/vocabulary_g3.pickle','wb')\n",
    "\n",
    "pickle.dump(new_words, complete_vocabulary)\n",
    "pickle.dump(vocabulary_latest, vocabulary_g3)\n",
    "\n",
    "complete_vocabulary.close()\n",
    "vocabulary_g3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./pickle/complete_vocabulary.pickle','rb')\n",
    "words = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(new_words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "int_to_vocab = {ii: word for ii, word in enumerate(vocab, 1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int_pickle = open('./pickle/vocab_to_int.pickle','wb')\n",
    "int_to_vocab_pickle = open('./pickle/int_to_vocab.pickle','wb')\n",
    "\n",
    "pickle.dump(vocab_to_int,vocab_to_int_pickle)\n",
    "pickle.dump(int_to_vocab,int_to_vocab_pickle)\n",
    "\n",
    "vocab_to_int_pickle.close()\n",
    "int_to_vocab_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# json.dumps(vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to tokenize the raw review and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_review(review):\n",
    "    tokens = []\n",
    "    for word in review.split(' '):\n",
    "        try:\n",
    "            token = vocab_to_int[word]\n",
    "            print(word, token)\n",
    "        except KeyError:\n",
    "            token = 0\n",
    "            print(word)\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoimmune\n",
      "diseases 418\n",
      "tend 1934\n",
      "to\n",
      "come 307\n",
      "in\n",
      "clusters.\n",
      "As\n",
      "for\n",
      "Gilenya\n",
      "– 68\n",
      "if\n",
      "you\n",
      "feel 128\n",
      "good,\n",
      "don’t 207\n",
      "think 79\n",
      "about\n",
      "it,\n",
      "it\n",
      "won’t 1577\n",
      "change 229\n",
      "anything 375\n",
      "but\n",
      "waste 4864\n",
      "your\n",
      "time 15\n",
      "and\n",
      "energy.\n",
      "I’m\n",
      "taking 69\n",
      "Tysabri\n",
      "and\n",
      "feel 128\n",
      "amazing,\n",
      "no\n",
      "symptoms 53\n",
      "(other\n",
      "than\n",
      "dodgy 11641\n",
      "color 2140\n",
      "vision,\n",
      "but\n",
      "I’ve\n",
      "had\n",
      "it\n",
      "since 59\n",
      "always,\n",
      "so,\n",
      "don’t 207\n",
      "know)\n",
      "and\n",
      "I\n",
      "don’t 207\n",
      "know 39\n",
      "if\n",
      "it\n",
      "will\n",
      "last 78\n",
      "a\n",
      "month,\n",
      "a\n",
      "year,\n",
      "a\n",
      "decade,\n",
      "ive 277\n",
      "just\n",
      "decided 946\n",
      "to\n",
      "enjoy 2442\n",
      "the\n",
      "ride,\n",
      "no\n",
      "point 419\n",
      "in\n",
      "worrying.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 418,\n",
       " 1934,\n",
       " 0,\n",
       " 307,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 68,\n",
       " 0,\n",
       " 0,\n",
       " 128,\n",
       " 0,\n",
       " 207,\n",
       " 79,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1577,\n",
       " 229,\n",
       " 375,\n",
       " 0,\n",
       " 4864,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 69,\n",
       " 0,\n",
       " 0,\n",
       " 128,\n",
       " 0,\n",
       " 0,\n",
       " 53,\n",
       " 0,\n",
       " 0,\n",
       " 11641,\n",
       " 2140,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 59,\n",
       " 0,\n",
       " 0,\n",
       " 207,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 207,\n",
       " 39,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 78,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 277,\n",
       " 0,\n",
       " 946,\n",
       " 0,\n",
       " 2442,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 419,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_review(list(train_csv.text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
