{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tshanmukh/sentiment_analysis/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWkYBE5QO2n",
        "colab_type": "text"
      },
      "source": [
        "# sentiment analysis project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_fl1tQQR9I",
        "colab_type": "code",
        "outputId": "26d86d51-2477-4577-c01e-ba7899ccaaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGUbY62SQWNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xunShkUVQO2o",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess and prepare a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuCvslpPQO2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQOYHxzFQO2t",
        "colab_type": "code",
        "outputId": "4a8ca2d7-b5c2-43a7-efb7-7e8c4972f087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reading the data to a csv\n",
        "# Reading the data from csv\n",
        "train_csv = pd.read_csv(root_path+'dataset/train.csv')\n",
        "print(len(train_csv.text))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOWOexDMQO2z",
        "colab_type": "code",
        "outputId": "38772d91-5a35-480e-9ac3-bc9dd111bef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "punctuation\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyEf1YQQO23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = ' '.join(list(train_csv.text))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq5UKIsutvT6",
        "colab_type": "text"
      },
      "source": [
        "## Creating a complete text in train csv to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVVGstDNQO29",
        "colab_type": "code",
        "outputId": "ca499518-8213-450d-87a2-fbd9afa1a348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import string\n",
        "\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()\n",
        "words[30:60]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taking',\n",
              " 'tysabri',\n",
              " 'and',\n",
              " 'feel',\n",
              " 'amazing',\n",
              " 'no',\n",
              " 'symptoms',\n",
              " 'other',\n",
              " 'than',\n",
              " 'dodgy',\n",
              " 'color',\n",
              " 'vision',\n",
              " 'but',\n",
              " 'i’ve',\n",
              " 'had',\n",
              " 'it',\n",
              " 'since',\n",
              " 'always',\n",
              " 'so',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'and',\n",
              " 'i',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'if',\n",
              " 'it',\n",
              " 'will',\n",
              " 'last',\n",
              " 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-b3_kyt4iz",
        "colab_type": "text"
      },
      "source": [
        "## Removing the punctuation, hyphen, and dash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F5g00jkQO3A",
        "colab_type": "code",
        "outputId": "feaaa786-814a-471d-e714-c5a33a2df27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "print(stripped[:100])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['autoimmune', 'diseases', 'tend', 'to', 'come', 'in', 'clusters', 'as', 'for', 'gilenya', '', 'if', 'you', 'feel', 'good', 'dont', 'think', 'about', 'it', 'it', 'wont', 'change', 'anything', 'but', 'waste', 'your', 'time', 'and', 'energy', 'im', 'taking', 'tysabri', 'and', 'feel', 'amazing', 'no', 'symptoms', 'other', 'than', 'dodgy', 'color', 'vision', 'but', 'ive', 'had', 'it', 'since', 'always', 'so', 'dont', 'know', 'and', 'i', 'dont', 'know', 'if', 'it', 'will', 'last', 'a', 'month', 'a', 'year', 'a', 'decade', 'ive', 'just', 'decided', 'to', 'enjoy', 'the', 'ride', 'no', 'point', 'in', 'worrying', 'i', 'can', 'completely', 'understand', 'why', 'youd', 'want', 'to', 'try', 'it', 'but', 'results', 'reported', 'in', 'lectures', 'dont', 'always', 'stand', 'up', 'to', 'the', 'scrutiny', 'of', 'peerreview']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Awp23YQO3E",
        "colab_type": "code",
        "outputId": "04938d65-dc42-4443-8e14-b5eaf29d0d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(stripped))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1786150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtEcpppyuCp_",
        "colab_type": "text"
      },
      "source": [
        "## Removing the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFyDfG2aQO3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_words = [word for word in stripped if word not in stopwords.words('english')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceKFWZxfQO3J",
        "colab_type": "code",
        "outputId": "09d62a9e-dd4a-4445-cc94-67a7c6737693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(new_words)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1058756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kub8nHUQO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabulary_latest = [word for word in new_words if len(word) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9s2ZJQJQO3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(vocabulary_latest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFx6NEbfQO3X",
        "colab_type": "text"
      },
      "source": [
        "# pickling the progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V528nPX7QO3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6h9pnVQO3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = open(root_path + 'pickle/vocabulary.pickle','wb')\n",
        "\n",
        "pickle.dump(new_words, vocabulary)\n",
        "\n",
        "vocabulary.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJlm1iZxuzbC",
        "colab_type": "text"
      },
      "source": [
        "## saved the progress of pre processing \n",
        "### Start from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKtgPNUvfyD",
        "colab_type": "code",
        "outputId": "102e58c9-2aa1-44c7-ef2c-f0e1452a6e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9N8uwuou5xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDRCZdgMQO3e",
        "colab_type": "code",
        "outputId": "72ea2e7a-2032-4a1d-b820-50215f9c627f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = open(root_path + 'pickle/vocabulary.pickle','rb')\n",
        "words = pickle.load(file)\n",
        "len(words), type(words)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1058756, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_hP88U0QO3j",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizing the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NDwghhrQO3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feel free to use this import \n",
        "from collections import Counter\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "int_to_vocab = {ii: word for ii, word in enumerate(vocab, 1)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHDEa4cQO3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int_pickle = open(root_path  + 'pickle/vocab_to_int.pickle','wb')\n",
        "int_to_vocab_pickle = open(root_path + 'pickle/int_to_vocab.pickle','wb')\n",
        "\n",
        "pickle.dump(vocab_to_int,vocab_to_int_pickle)\n",
        "pickle.dump(int_to_vocab,int_to_vocab_pickle)\n",
        "\n",
        "vocab_to_int_pickle.close()\n",
        "int_to_vocab_pickle.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLZnIuFQO3z",
        "colab_type": "text"
      },
      "source": [
        "# Functions to tokenize the raw review and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgbAwvPTw-q7",
        "colab_type": "code",
        "outputId": "f4e8313f-5960-42fb-ce27-64f5f1983270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klR3E_cTQO30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def tokenize_review(review):\n",
        "    \n",
        "    words = review.lower().split(' ')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    review = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "    # review = ''.join([c for c in review if c not in punctuation])\n",
        "    tokens = []\n",
        "    for word in review:\n",
        "      \n",
        "        try:\n",
        "            token = vocab_to_int[word]\n",
        "            # print(word, token)\n",
        "        except KeyError:\n",
        "            token = 0\n",
        "            # print(word, token)\n",
        "        tokens.append(token)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HciTJCm7QO32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "review_tokens = tokenize_review(list(train_csv.text)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaFKMYfQO36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_setiment(label):\n",
        "  if label == '0' or label == 0:\n",
        "    return [0, 0, 0]\n",
        "  elif label == '1' or label == 1:\n",
        "    return [0, 1, 0]\n",
        "  elif label == '2' or label == 2:\n",
        "    return [0, 0, 1]\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GupoQj5kUUUe",
        "colab_type": "code",
        "outputId": "b3b3242f-7faf-400b-edeb-d5e669b2f80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenize_setiment(list(train_csv.sentiment)[2000])"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdzyz_ZtxU-B",
        "colab_type": "text"
      },
      "source": [
        "## parse the review based on the drug and tokenize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHH4Qd_c06gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "drugs = set([w.translate(table).replace('’','').replace('–','').lower() for w in set(train_csv.drug)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFloY63cUiHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import LineTokenizer\n",
        "\n",
        "def parse_review(review, drug, drugs_list):\n",
        "  tk = LineTokenizer()\n",
        "  lines = tk.tokenize(review)\n",
        "  review = ''.join(lines)\n",
        "  sentenses = review.lower().split('.')\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  drugs_list.remove(drug)\n",
        "  drug = drug.translate(table).replace('’','').replace('–','').lower()\n",
        "  token =[]\n",
        "  for sentense in sentenses:\n",
        "    review = set([w.translate(table).replace('’','').replace('–','') for w in sentense.split(' ') if w != ''])\n",
        "    if drugs_list & review:\n",
        "      continue\n",
        "      # print(\"Not expecting\", drugs_list & review, \"expecting only \",drug)\n",
        "    else:\n",
        "      token.extend(tokenize_review(sentense))\n",
        "  return token\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTnsKC2i4kz",
        "colab_type": "code",
        "outputId": "97e32c73-b0b4-4e5c-abad-b3ac132aa103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(train_csv.loc[10,'text'])\n",
        "print(train_csv.loc[10,'drug'])\n",
        "drugs_list = drugs.copy()\n",
        "# print(len(train_csv.loc[10,'text'].split(' ')))\n",
        "token = parse_review(train_csv.loc[10,'text'],train_csv.loc[10,'drug'], drugs_list)\n",
        "# print(len(token))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have no vision in one eye, unrelated to my eye injections. However, when problems began in my good eye, getting injections in that one and only eye is always a horrifying experience - mentally. It is still scary till today, you don't get used to it. I have had many eye injections. My first was when I was 43 years old, 7 years ago. I developed an eye infection, but no one could pinpoint what it exactly was. So one by one, every antibiotic was injected in the eye for a period of 6 weeks, and totalling 24 injections. It was a big relief when the last antibiotic available did the job, as there were no other options left after that. Two years later, I had cataract surgery. Within a week I developed retinal vein occlusion. Also, macular oedema came into play as well. And so began the Avasrin injections and then Lucentis. I would be getting them very frequently. And a year later, it became monthly injections. I have now stopped counting. Sometimes after an injection, it becomes pitch black for me. The first time I was terrified. But then I was told it was due to eye pressured and after a few Injures, all came back to normal. Main thing is I make sure what may or may not happen with the procedure and eye condition, so at least I am prepared. It's true, in Australia, neither Lucentis nor Eylea were covered by the government unless one had macular degeneration. Even though the other conditions are also vision threatening. Eylea has extended the time period between each of my injections, and that is the biggest milestone achieved to date. I am so grateful to my ALL of my ophthalmologists who have gone above and beyond their profession, to make the injection process as comfortable as they possibly can for me. And as for the researchers, well done and keep it going. The eye is priceless.\n",
            "lucentis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOCTvf6FHcd",
        "colab_type": "text"
      },
      "source": [
        "# Creating a dataset from the train_csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRhudvPRFGe1",
        "colab_type": "code",
        "outputId": "faf3e872-8ad3-4d4e-f4ae-04fb23447980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "text_dataset = []\n",
        "label_dataset = []\n",
        "for review in tqdm(zip(train_csv.text, train_csv.drug, train_csv.sentiment)):\n",
        "  drugs_list = drugs.copy()\n",
        "  text_dataset.append(parse_review(review[0],review[1].translate(table).replace('’','').replace('–','').lower(), drugs_list)) #added the preprocess for drugname\n",
        "  label_dataset.append(tokenize_setiment(review[2]))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5279it [00:04, 1143.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmsf2U7gH1d4",
        "colab_type": "code",
        "outputId": "b15fba03-3a4b-4e29-df80-ade702de5526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "reviews_ints = text_dataset.copy()\n",
        "encoded_labels = label_dataset.copy()\n",
        "\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  5279\n",
            "Number of reviews after removing outliers:  5233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz9WYvyjKFjB",
        "colab_type": "code",
        "outputId": "b4e43227-4f2e-44e5-fd30-f4d06865aea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "text_dataset, label_dataset = None, None\n",
        "print(encoded_labels)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " ...\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5RrcSjbAFTw",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJz351qfEREx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUgibrRQi4kD",
        "colab_type": "code",
        "outputId": "814c0341-e609-4f6f-e2d5-87a41c489744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "lengths =[]\n",
        "for rev in reviews_ints:\n",
        "  lengths.append(len(rev))\n",
        "print(max(lengths))\n",
        "%matplotlib inline\n",
        "plt.plot(lengths)\n",
        "plt.show()\n",
        "\n",
        "lengths = None\n",
        "\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZQs/03SbGv4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQY6eyR9i4jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMV96afqi4h5",
        "colab_type": "code",
        "outputId": "ec1c68b3-9cc2-4501-ff9c-5340462642ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_length = 1400\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "# ## test statements - do not change - ##\n",
        "# assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "# assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches \n",
        "print(features.shape)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5233, 1400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7wBZc9CK3DB",
        "colab_type": "text"
      },
      "source": [
        "# Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoIJq-jg3Am",
        "colab_type": "code",
        "outputId": "7320cfb3-8b75-430b-e5aa-f9d6d8f0e5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
        "\n",
        "features= None"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(4186, 1400) \n",
            "Validation set: \t(523, 1400) \n",
            "Test set: \t\t(524, 1400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlRw02JULJGM",
        "colab_type": "text"
      },
      "source": [
        "# dataloaders and batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZb81qlKK_4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 20\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHEvfh6f906k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "820c3bc6-7391-40f8-ecf6-114147e73f5c"
      },
      "source": [
        "dir(train_data)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'tensors']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUz-DGksLHPz",
        "colab_type": "code",
        "outputId": "8b1be0e3-bd0e-4720-d955-fdeabdfed5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([20, 1400])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,  2071,    62,  3941],\n",
            "        [    0,     0,     0,  ...,     5,   461,    70],\n",
            "        [    0,     0,     0,  ...,   577,   755,    70],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,    36,     0,    70],\n",
            "        [    0,     0,     0,  ...,    70, 17255,    70],\n",
            "        [    0,     0,     0,  ...,   232,    70, 22236]])\n",
            "\n",
            "Sample label size:  torch.Size([20, 3])\n",
            "Sample label: \n",
            " tensor([[0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 1, 0],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFvmRcCcL1ux",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-r6MZk0LtMp",
        "colab_type": "code",
        "outputId": "ce6ed08e-55e3-4f91-b5a2-81ff6793dc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "  print(\"Training on GPU\")\n",
        "else:\n",
        "  print('No GPU available. Training on CPU')"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV-cz0ngMAvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Softmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # print(out.shape)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1, 3)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pApisARZRVAf",
        "colab_type": "code",
        "outputId": "d7d274b3-9c20-4e83-b96d-c35b6a27a303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(53133, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (sig): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2YsLZHRbph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPr7yJLhTqYm",
        "colab_type": "code",
        "outputId": "a140edb5-2faf-49e9-b140-3ca14ff0c11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "\n",
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "    # net.to('cuda')\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        # labels = torch.tensor(labels, dtype=torch.long)\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "        # print(inputs.shape)\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "        # print(output.shape, labels.shape)\n",
        "        # calculate the loss and perform backprop\n",
        "\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                # labels = torch.tensor(labels, dtype=torch.long)\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                    \n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-207-64292ae01dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# move model to GPU, if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# net.to('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZX64riBTxhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}