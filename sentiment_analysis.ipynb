{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tshanmukh/sentiment_analysis/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWkYBE5QO2n",
        "colab_type": "text"
      },
      "source": [
        "# sentiment analysis project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_fl1tQQR9I",
        "colab_type": "code",
        "outputId": "d579a5df-e244-48af-9ffe-b23ca63a2302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGUbY62SQWNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xunShkUVQO2o",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess and prepare a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuCvslpPQO2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQOYHxzFQO2t",
        "colab_type": "code",
        "outputId": "afe5dbb9-23b2-4bf7-96b5-0dff57c6375f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reading the data to a csv\n",
        "# Reading the data from csv\n",
        "train_csv = pd.read_csv(root_path+'dataset/train.csv')\n",
        "print(len(train_csv.text))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOWOexDMQO2z",
        "colab_type": "code",
        "outputId": "608e5035-9bcc-4c4e-988a-58a1ed2938d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "punctuation\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyEf1YQQO23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = ' '.join(list(train_csv.text))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq5UKIsutvT6",
        "colab_type": "text"
      },
      "source": [
        "## Creating a complete text in train csv to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVVGstDNQO29",
        "colab_type": "code",
        "outputId": "eb7016e3-de1f-443b-83ea-f955fcb8906d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import string\n",
        "\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()\n",
        "words[30:60]"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taking',\n",
              " 'tysabri',\n",
              " 'and',\n",
              " 'feel',\n",
              " 'amazing',\n",
              " 'no',\n",
              " 'symptoms',\n",
              " 'other',\n",
              " 'than',\n",
              " 'dodgy',\n",
              " 'color',\n",
              " 'vision',\n",
              " 'but',\n",
              " 'i’ve',\n",
              " 'had',\n",
              " 'it',\n",
              " 'since',\n",
              " 'always',\n",
              " 'so',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'and',\n",
              " 'i',\n",
              " 'don’t',\n",
              " 'know',\n",
              " 'if',\n",
              " 'it',\n",
              " 'will',\n",
              " 'last',\n",
              " 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-b3_kyt4iz",
        "colab_type": "text"
      },
      "source": [
        "## Removing the punctuation, hyphen, and dash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F5g00jkQO3A",
        "colab_type": "code",
        "outputId": "eb448ec2-e6f3-4e62-b066-4455b18a92f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "print(stripped[:100])\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['autoimmune', 'diseases', 'tend', 'to', 'come', 'in', 'clusters', 'as', 'for', 'gilenya', '', 'if', 'you', 'feel', 'good', 'dont', 'think', 'about', 'it', 'it', 'wont', 'change', 'anything', 'but', 'waste', 'your', 'time', 'and', 'energy', 'im', 'taking', 'tysabri', 'and', 'feel', 'amazing', 'no', 'symptoms', 'other', 'than', 'dodgy', 'color', 'vision', 'but', 'ive', 'had', 'it', 'since', 'always', 'so', 'dont', 'know', 'and', 'i', 'dont', 'know', 'if', 'it', 'will', 'last', 'a', 'month', 'a', 'year', 'a', 'decade', 'ive', 'just', 'decided', 'to', 'enjoy', 'the', 'ride', 'no', 'point', 'in', 'worrying', 'i', 'can', 'completely', 'understand', 'why', 'youd', 'want', 'to', 'try', 'it', 'but', 'results', 'reported', 'in', 'lectures', 'dont', 'always', 'stand', 'up', 'to', 'the', 'scrutiny', 'of', 'peerreview']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Awp23YQO3E",
        "colab_type": "code",
        "outputId": "8df97829-2ba3-432d-b3ea-b380f6711843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(stripped))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1786150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtEcpppyuCp_",
        "colab_type": "text"
      },
      "source": [
        "## Removing the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFyDfG2aQO3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_words = [word for word in stripped if word not in stopwords.words('english')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceKFWZxfQO3J",
        "colab_type": "code",
        "outputId": "0a7eb9c2-6b89-49ef-9148-ba960b64e262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(new_words)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1058756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kub8nHUQO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabulary_latest = [word for word in new_words if len(word) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9s2ZJQJQO3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(vocabulary_latest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFx6NEbfQO3X",
        "colab_type": "text"
      },
      "source": [
        "# pickling the progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V528nPX7QO3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6h9pnVQO3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = open(root_path + 'pickle/vocabulary.pickle','wb')\n",
        "\n",
        "pickle.dump(new_words, vocabulary)\n",
        "\n",
        "vocabulary.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJlm1iZxuzbC",
        "colab_type": "text"
      },
      "source": [
        "## saved the progress of pre processing \n",
        "### Start from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKtgPNUvfyD",
        "colab_type": "code",
        "outputId": "042b0882-fd63-4e69-e996-39dff307604e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9N8uwuou5xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import plotly.offline as pyo\n",
        "from string import punctuation\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/sentiment_analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDRCZdgMQO3e",
        "colab_type": "code",
        "outputId": "8ed79222-9377-480a-dca2-f7904e33ac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = open(root_path + 'pickle/vocabulary.pickle','rb')\n",
        "words = pickle.load(file)\n",
        "len(words), type(words)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1058756, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_hP88U0QO3j",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizing the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NDwghhrQO3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feel free to use this import \n",
        "from collections import Counter\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "int_to_vocab = {ii: word for ii, word in enumerate(vocab, 1)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHDEa4cQO3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int_pickle = open(root_path  + 'pickle/vocab_to_int.pickle','wb')\n",
        "int_to_vocab_pickle = open(root_path + 'pickle/int_to_vocab.pickle','wb')\n",
        "\n",
        "pickle.dump(vocab_to_int,vocab_to_int_pickle)\n",
        "pickle.dump(int_to_vocab,int_to_vocab_pickle)\n",
        "\n",
        "vocab_to_int_pickle.close()\n",
        "int_to_vocab_pickle.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLZnIuFQO3z",
        "colab_type": "text"
      },
      "source": [
        "# Functions to tokenize the raw review and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgbAwvPTw-q7",
        "colab_type": "code",
        "outputId": "139a730f-d9c6-4b77-93b1-260b17d7ee7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# imports for nltk stop words\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klR3E_cTQO30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def tokenize_review(review):\n",
        "    \n",
        "    words = review.lower().split(' ')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    review = [w.translate(table).replace('’','').replace('–','') for w in words]\n",
        "    # review = ''.join([c for c in review if c not in punctuation])\n",
        "    tokens = []\n",
        "    for word in review:\n",
        "      \n",
        "        try:\n",
        "            token = vocab_to_int[word]\n",
        "            # print(word, token)\n",
        "        except KeyError:\n",
        "            token = 0\n",
        "            # print(word, token)\n",
        "        tokens.append(token)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HciTJCm7QO32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "review_tokens = tokenize_review(list(train_csv.text)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaFKMYfQO36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_setiment(label):\n",
        "  if label == '0' or label == 0:\n",
        "    return 0\n",
        "  elif label == '1' or label == 1:\n",
        "    return 1\n",
        "  elif label == '2' or label == 2:\n",
        "    return 2\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GupoQj5kUUUe",
        "colab_type": "code",
        "outputId": "bf243854-ced7-4199-a619-c8af3b93092b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenize_setiment(list(train_csv.sentiment)[2000])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdzyz_ZtxU-B",
        "colab_type": "text"
      },
      "source": [
        "## parse the review based on the drug and tokenize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHH4Qd_c06gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "drugs = set([w.translate(table).replace('’','').replace('–','').lower() for w in set(train_csv.drug)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFloY63cUiHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import LineTokenizer\n",
        "\n",
        "def parse_review(review, drug, drugs_list):\n",
        "  tk = LineTokenizer()\n",
        "  lines = tk.tokenize(review)\n",
        "  review = ''.join(lines)\n",
        "  sentenses = review.lower().split('.')\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  drugs_list.remove(drug)\n",
        "  drug = drug.translate(table).replace('’','').replace('–','').lower()\n",
        "  token =[]\n",
        "  for sentense in sentenses:\n",
        "    review = set([w.translate(table).replace('’','').replace('–','') for w in sentense.split(' ') if w != ''])\n",
        "    if drugs_list & review:\n",
        "      continue\n",
        "      # print(\"Not expecting\", drugs_list & review, \"expecting only \",drug)\n",
        "    else:\n",
        "      token.extend(tokenize_review(sentense))\n",
        "  return token\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTnsKC2i4kz",
        "colab_type": "code",
        "outputId": "6260633f-bb66-427f-e7b4-63184262deb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(train_csv.loc[10,'text'])\n",
        "print(train_csv.loc[10,'drug'])\n",
        "drugs_list = drugs.copy()\n",
        "# print(len(train_csv.loc[10,'text'].split(' ')))\n",
        "token = parse_review(train_csv.loc[10,'text'],train_csv.loc[10,'drug'], drugs_list)\n",
        "print(token)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have no vision in one eye, unrelated to my eye injections. However, when problems began in my good eye, getting injections in that one and only eye is always a horrifying experience - mentally. It is still scary till today, you don't get used to it. I have had many eye injections. My first was when I was 43 years old, 7 years ago. I developed an eye infection, but no one could pinpoint what it exactly was. So one by one, every antibiotic was injected in the eye for a period of 6 weeks, and totalling 24 injections. It was a big relief when the last antibiotic available did the job, as there were no other options left after that. Two years later, I had cataract surgery. Within a week I developed retinal vein occlusion. Also, macular oedema came into play as well. And so began the Avasrin injections and then Lucentis. I would be getting them very frequently. And a year later, it became monthly injections. I have now stopped counting. Sometimes after an injection, it becomes pitch black for me. The first time I was terrified. But then I was told it was due to eye pressured and after a few Injures, all came back to normal. Main thing is I make sure what may or may not happen with the procedure and eye condition, so at least I am prepared. It's true, in Australia, neither Lucentis nor Eylea were covered by the government unless one had macular degeneration. Even though the other conditions are also vision threatening. Eylea has extended the time period between each of my injections, and that is the biggest milestone achieved to date. I am so grateful to my ALL of my ophthalmologists who have gone above and beyond their profession, to make the injection process as comfortable as they possibly can for me. And as for the researchers, well done and keep it going. The eye is priceless.\n",
            "lucentis\n",
            "[0, 0, 0, 242, 0, 8, 152, 4836, 0, 0, 152, 349, 70, 136, 0, 180, 851, 0, 0, 42, 152, 158, 349, 0, 0, 8, 0, 0, 152, 0, 292, 0, 12838, 270, 70, 4529, 70, 0, 0, 57, 1931, 2968, 273, 0, 52, 18, 39, 0, 0, 70, 0, 0, 0, 69, 152, 349, 70, 0, 22, 0, 0, 0, 0, 2214, 10, 391, 249, 10, 124, 70, 0, 436, 0, 152, 160, 0, 0, 8, 44, 6880, 0, 0, 1652, 0, 70, 0, 8, 0, 8, 66, 2969, 0, 1287, 0, 0, 152, 0, 0, 600, 0, 77, 34, 0, 20323, 546, 349, 70, 0, 0, 0, 466, 1499, 0, 0, 79, 2969, 135, 0, 0, 1247, 0, 0, 0, 0, 0, 290, 339, 0, 0, 70, 35, 10, 360, 0, 0, 1127, 45, 70, 277, 0, 78, 0, 436, 537, 993, 1871, 70, 7, 347, 1687, 592, 0, 1320, 0, 36, 70, 0, 0, 851, 0, 28570, 349, 0, 0, 1033, 70, 0, 19, 0, 158, 0, 0, 1500, 70, 0, 0, 48, 360, 0, 1341, 1265, 349, 70, 0, 0, 0, 522, 6123, 70, 355, 0, 0, 178, 0, 1653, 11579, 1851, 0, 0, 70, 0, 22, 16, 0, 0, 4955, 70, 0, 0, 0, 0, 245, 0, 0, 199, 0, 152, 14334, 0, 0, 0, 0, 20324, 0, 592, 58, 0, 312, 70, 793, 288, 0, 0, 88, 182, 0, 4, 0, 4, 0, 892, 0, 0, 740, 0, 152, 429, 0, 0, 187, 0, 0, 2669, 70, 74, 313, 0, 0, 539, 0, 7, 242, 5734, 70, 0, 0, 0, 2237, 0, 0, 0, 0, 0, 6881, 0, 0, 874, 0, 0, 1321, 0, 10675, 0, 88, 0, 178, 586, 0, 2583, 0, 0, 1147, 0, 0, 0, 70, 0, 0, 0, 0, 388, 36, 198, 0, 181, 0, 111, 70, 0, 152, 0, 28571, 70]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOCTvf6FHcd",
        "colab_type": "text"
      },
      "source": [
        "# Creating a dataset from the train_csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRhudvPRFGe1",
        "colab_type": "code",
        "outputId": "2f48c69a-52e3-44c9-b972-d4ae041ed8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "text_dataset = []\n",
        "label_dataset = []\n",
        "for review in tqdm(zip(train_csv.text, train_csv.drug, train_csv.sentiment)):\n",
        "  drugs_list = drugs.copy()\n",
        "  text_dataset.append(parse_review(review[0],review[1].translate(table).replace('’','').replace('–','').lower(), drugs_list)) #added the preprocess for drugname\n",
        "  label_dataset.append(tokenize_setiment(review[2]))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5279it [00:04, 1118.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7uXLe8qqg6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba43d9cd-aaae-4666-a35c-a1a0b6b45183"
      },
      "source": [
        "len(text_dataset), len(label_dataset) "
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279, 5279)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmsf2U7gH1d4",
        "colab_type": "code",
        "outputId": "237a9a4d-ab05-430c-baf6-7c55de39fcca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "reviews_ints = text_dataset.copy()\n",
        "encoded_labels = label_dataset.copy()\n",
        "\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  5279\n",
            "Number of reviews after removing outliers:  5233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz9WYvyjKFjB",
        "colab_type": "code",
        "outputId": "8257b7e8-c1aa-4eda-db5b-eaeebc002f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_dataset, label_dataset = None, None\n",
        "print(encoded_labels)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 ... 2 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5RrcSjbAFTw",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJz351qfEREx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUgibrRQi4kD",
        "colab_type": "code",
        "outputId": "d5793745-1375-4049-b12f-03774d1d5208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "lengths =[]\n",
        "for rev in reviews_ints:\n",
        "  lengths.append(len(rev))\n",
        "print(max(lengths))\n",
        "%matplotlib inline\n",
        "plt.plot(lengths)\n",
        "plt.show()\n",
        "\n",
        "# sum(lengths)/len(lengths)\n",
        "lengths = None"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZQs/03SbGv4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQY6eyR9i4jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMV96afqi4h5",
        "colab_type": "code",
        "outputId": "91d54b6f-ea0c-41cb-cfc0-99b0b6e88a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_length = 600\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "# ## test statements - do not change - ##\n",
        "# assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "# assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches \n",
        "print(features.shape)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5233, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7wBZc9CK3DB",
        "colab_type": "text"
      },
      "source": [
        "# Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoIJq-jg3Am",
        "colab_type": "code",
        "outputId": "116222aa-3b93-4578-c0e0-1ae8fc1fc9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "# test_idx = int(len(remaining_x)*0.5)\n",
        "# val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "# val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "val_x = remaining_x\n",
        "val_y = remaining_y\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape))\n",
        "\n",
        "features= None\n",
        "train_y.shape"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(4186, 600) \n",
            "Validation set: \t(1047, 600)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4186,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlRw02JULJGM",
        "colab_type": "text"
      },
      "source": [
        "# dataloaders and batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZb81qlKK_4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "# test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True )\n",
        "# test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1icgJNfJnScL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUz-DGksLHPz",
        "colab_type": "code",
        "outputId": "939277ca-657f-4e1a-a73e-b1c3a4c46a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 600])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,    0,  429,   70],\n",
            "        [   0,    0,    0,  ...,  155,    0,  232],\n",
            "        [   0,    0,    0,  ...,  200,  142,    0],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ..., 3840,   11,   70],\n",
            "        [1473,    0, 1790,  ...,   96, 2038, 3722],\n",
            "        [   0,    0,    0,  ...,   42,    0,   70]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([1, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2,\n",
            "        2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFvmRcCcL1ux",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-r6MZk0LtMp",
        "colab_type": "code",
        "outputId": "bf318e74-4714-4214-8c87-cc309736075f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "  print(\"Training on GPU\")\n",
        "else:\n",
        "  print('No GPU available. Training on CPU')"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV-cz0ngMAvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # print(out.shape)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        # sig_out = out\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1, 3)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pApisARZRVAf",
        "colab_type": "code",
        "outputId": "0c08238c-4a73-4eab-e1a3-d93533e97f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "\n",
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(53133, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (sig): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2YsLZHRbph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPr7yJLhTqYm",
        "colab_type": "code",
        "outputId": "788fc44c-917e-4cac-f6d3-6edfcad6ea76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "\n",
        "# training params\n",
        "\n",
        "epochs = 25 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "    # net.to('cuda')\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        # labels = torch.tensor(labels, dtype=torch.long)\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "        # print(inputs.shape)\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "        # print(output.shape, labels.shape)\n",
        "        # calculate the loss and perform backprop\n",
        "       \n",
        "        loss = criterion(output.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.squeeze())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(val_loss))\n",
        "\n"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 100... Loss: 0.562104... Val Loss: 0.805446\n",
            "Epoch: 2/25... Step: 200... Loss: 0.579568... Val Loss: 0.687330\n",
            "Epoch: 3/25... Step: 300... Loss: 0.489245... Val Loss: 0.959798\n",
            "Epoch: 4/25... Step: 400... Loss: 0.374069... Val Loss: 1.163930\n",
            "Epoch: 6/25... Step: 500... Loss: 0.099462... Val Loss: 0.783987\n",
            "Epoch: 7/25... Step: 600... Loss: 0.065502... Val Loss: 1.784991\n",
            "Epoch: 8/25... Step: 700... Loss: 0.112600... Val Loss: 2.205741\n",
            "Epoch: 9/25... Step: 800... Loss: 0.097045... Val Loss: 1.527392\n",
            "Epoch: 10/25... Step: 900... Loss: 0.184952... Val Loss: 1.927248\n",
            "Epoch: 12/25... Step: 1000... Loss: 0.078104... Val Loss: 1.693563\n",
            "Epoch: 13/25... Step: 1100... Loss: 0.018976... Val Loss: 1.769388\n",
            "Epoch: 14/25... Step: 1200... Loss: 0.095444... Val Loss: 2.227190\n",
            "Epoch: 15/25... Step: 1300... Loss: 0.131905... Val Loss: 2.456124\n",
            "Epoch: 16/25... Step: 1400... Loss: 0.134120... Val Loss: 2.725529\n",
            "Epoch: 18/25... Step: 1500... Loss: 0.016718... Val Loss: 2.098311\n",
            "Epoch: 19/25... Step: 1600... Loss: 0.005994... Val Loss: 2.392923\n",
            "Epoch: 20/25... Step: 1700... Loss: 0.014991... Val Loss: 4.151257\n",
            "Epoch: 21/25... Step: 1800... Loss: 0.013836... Val Loss: 1.916076\n",
            "Epoch: 22/25... Step: 1900... Loss: 0.044727... Val Loss: 3.785940\n",
            "Epoch: 24/25... Step: 2000... Loss: 0.003419... Val Loss: 1.912212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_oh_wFWnQ0",
        "colab_type": "text"
      },
      "source": [
        "## Loading and testing the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZX64riBTxhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4db7fb7c-2598-4693-9abf-a2f20a71b54d"
      },
      "source": [
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "# model_test = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "# model_test.load_state_dict(torch.load(root_path+'/model.pt'),strict=False)\n",
        "# if train_on_gpu:\n",
        "#   print(\"using GPU\")\n",
        "#   model_test.cuda()\n",
        "# model_test.eval()\n",
        "\n",
        "# for param in model_test.parameters():\n",
        "#   print(param.data)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(53133, 400)\n",
              "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              "  (sig): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iicRcHshW9RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ebb72c9d-9d8f-42eb-d89b-ec9b09eeddf0"
      },
      "source": [
        "test_csv = pd.read_csv(root_path + 'dataset/test.csv')\n",
        "test_csv.head()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>On fingolimod and have been since December 201...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
              "      <td>humira</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
              "      <td>tagrisso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
              "      <td>stelara</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ...        drug\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08  ...  fingolimod\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  ...  fingolimod\n",
              "2  50b6d851bcff4f35afe354937949e9948975adf7  ...      humira\n",
              "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae  ...    tagrisso\n",
              "4  8b37d169dee5bdae27060949242fb54feb6a7f7f  ...     stelara\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDHUBe6qYYNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "37dd172b-09c3-4bc5-8287-324d80f7c269"
      },
      "source": [
        "# parse_review(review[0],review[1].translate(table).replace('’','').replace('–','').lower(), drugs_list)\n",
        "\n",
        "list(test_csv.text)[20], list(test_csv.drug)[20],"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"You are overthinking this. Just ask her out and see if she accepts first. If she says yes, then you can discuss where you'd like to go that would suit both of you. If she wants to talk about her Crohn's, then listen to her, but I wouldn't mention it until she does to be honest. Ditto the unsympathetic ex. Dx Crohn's in June 2000. (Yay  ) Tried: 5-ASAs, azathioprine, 6MP, Remicade, methotrexate, Humira, diets. 1st surgery 20/2/13 - subtotal colectomy with end ileostomy. 2nd surgery 10/7/15 - ileorectal anastomosis. Stoma reversed and ileum connected to the rectum. Current status: Chronic flare. Do I have any other kind? Current meds: 50mg 6MP; Entyvio (started 3/11/16)\",\n",
              " 'remicade')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVBYk_YZyRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijX0xsyaWkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentiment(review, drug):\n",
        "  drugs_list = drugs.copy()\n",
        "  test_review = parse_review(list(test_csv.text)[200], list(test_csv.drug)[200], drugs_list)\n",
        "  test_input = pad_features([test_review], 600)\n",
        "  test_input = np.array(test_input)\n",
        "  # initialize hidden state\n",
        "  h = net.init_hidden(1)\n",
        "  feature_tensor = torch.from_numpy(test_input)\n",
        "    \n",
        "  batch_size = feature_tensor.size(0)\n",
        "  if(train_on_gpu):\n",
        "    feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "  # get the output from the model\n",
        "  output, h = net(feature_tensor, h)  \n",
        "  return torch.exp(output).topk(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNydsvF_b_so",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(root_path+'submission.csv','w')\n",
        "file.write(\"unique_hash,sentiment\\n\")\n",
        "\n",
        "for i in zip(test_csv.unique_hash, test_csv.text, test_csv.drug):\n",
        "  logits = get_sentiment(i[1], i[2])\n",
        "  file.write(\"{},{}\\n\".format(i[0],*logits.indices[0].to('cpu').numpy()))\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLivckmcLz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "097886aa-1b77-4783-9b94-548fbd850964"
      },
      "source": [
        "sub = pd.read_csv(root_path+'submission.csv')\n",
        "set(sub.sentiment)\n"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqKw_rYac6Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Z8wn6icW0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVejbLTldz-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}